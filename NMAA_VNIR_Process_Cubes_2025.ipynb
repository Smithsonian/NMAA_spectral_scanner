{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Processing spectral data cube files\n",
    "#This is intended to process a collection of .cube and .hdr files generated from a Surface Optics Camera on motorized rail\n",
    "#A set of file names should be created as a text file\n",
    "#A step in this process is creating a calibration file in ENVI. That step is not detailed here.\n",
    "#Matthew Clarke, National Museum of Asian Art, Smithsonian Institution, 2025-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "%matplotlib qt \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from spectral import *\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the directory, field file\n",
    "os.chdir('D:\\\\Processing-XRF\\\\Datafolder') #set the location of the files; sometimes this needs \\\\\n",
    "flatfile='flatfield_cubefile' #no extension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the flatfield file, get mean, create new image cube that matches the calibration standards image\n",
    "sflat=envi.open(flatfile+'.hdr',flatfile+'.cube')\n",
    "sarrflat = sflat.load()\n",
    "#Get the mean of the movement axis\n",
    "sarrflatmean=np.mean(sarrflat, axis=0) #get the aveage of the movement axis\n",
    "totalrows=256 #this should match calibration standards image size\n",
    "sarrflatmeanbig = np.repeat(sarrflatmean[:, np.newaxis, :], totalrows, axis=1)\n",
    "sarrflatmeanbig = np.swapaxes(sarrflatmeanbig, 0,1) #need to rearrange axis to match original data order\n",
    "metaout = sflat.metadata.copy()\n",
    "metaout['bands']=str(totalrows)\n",
    "flatfileout=flatfile[0:-6] #remove existing extension\n",
    "envi.save_image(flatfileout+'_mean.hdr', sarrflatmeanbig, dtype=np.float32, interleave='bil', metadata=metaout, ext='.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab5d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now complete calibration processing in ENVI\n",
    "#This is using spectral math S1/S2, where S1 is the calibration image, and S2 is the flatfiled\n",
    "#Next perform empirical line calibration based on reflectance standards.\n",
    "#Save the .cff file for use in batch processing of all sample cubes.\n",
    "#Create a txt file of the sample cubes for batch processing. This is the .hdr files list only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b019181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the cff file and sample file list.\n",
    "calfile='cff_RefStds_VNIR_20241216_160ms_f4_Effilux-100.cff' #with cff ext; need to create in ENVI \n",
    "\n",
    "filelistfile='batchcontents.txt' #list of .hdr files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2aaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of files as an array that will be processed\n",
    "with open(filelistfile, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    filelist = list(reader)\n",
    "filelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the calibration and flat field files\n",
    "calarr=np.genfromtxt(calfile, skip_header=5, delimiter=\"\")\n",
    "sflat=envi.open(flatfile+'.hdr',flatfile+'.cube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71520c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load Sample cubes and flat field and calibrate and crop edge pixels, and crop spectra, save new cubes.\n",
    "#This data has cubes from the VNIR chip = 1024x1024, and 256 bands.\n",
    "#The spectral response past 1000 nm was very low signal as the NIR LEDs do not extend this far. This is cropped from final cubes.\n",
    "#cropping the ends of the spatial part of the cube can eliminate low signal areas and lines where the camera movement is not yet consistent. \n",
    "rowstart = 4 #0 index\n",
    "rowend = 1020 #this is +1 of end\n",
    "samplestart = 4\n",
    "sampleend = 1020\n",
    "bandstart = 0\n",
    "bandend = 236\n",
    "for fileiter in range(0, len(filelist)): #range needs to go to end\n",
    "    datafile=str(filelist[fileiter])\n",
    "    datafile=datafile[2:-6] #remove existing extension\n",
    "    sdata=envi.open(datafile+'.hdr',datafile+'.cube')\n",
    "    totalrows = sdata.metadata['lines'] #this should match the sample total rows\n",
    "    sarrflatmeanbig = np.repeat(sarrflatmean[:, np.newaxis, :], totalrows, axis=1)\n",
    "    sarrflatmeanbig = np.swapaxes(sarrflatmeanbig, 0,1) #need to rearrange axis to match original data order\n",
    "    sarrdata = sdata.load()\n",
    "    sarrdataproc=np.ndarray(shape=sarrdata.shape, dtype=float)\n",
    "    #calibrate file\n",
    "    for b in range(0, sarrdata.shape[2]): #range needs to go to end\n",
    "        sarrdataproc[:,:,b]=((np.squeeze(sarrdata[:,:,b])/np.squeeze(sarrflatmeanbig[:,:,b]))-calarr[b,2])/calarr[b,1] #correct formula\n",
    "    #crop file\n",
    "    subproc=sarrdataproc[rowstart:rowend, samplestart:sampleend, bandstart:bandend]\n",
    "    cropmeta = sdata.metadata.copy()\n",
    "    cropmeta['wavelength']=sdata.metadata['wavelength'][bandstart:bandend]\n",
    "    cropmeta['bands']=str(bandend-bandstart)\n",
    "    cropmeta['samples']=str(sampleend-samplestart)\n",
    "    cropmeta['lines']=str(rowend-rowstart)\n",
    "    #Save the file with cropping\n",
    "    calcropout='crcff_'+datafile+'.hdr'\n",
    "    envi.save_image(calcropout, subproc, dtype=np.float32, interleave='bil', metadata=cropmeta, ext='.dat')\n",
    "    print(fileiter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
